# ============================================================================
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ¦Ø© (ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø£ÙˆÙ„Ø§Ù‹)
# ============================================================================
import os
import warnings

os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ ÙÙ‚Ø·
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
warnings.filterwarnings('ignore')

# ============================================================================
# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª
# ============================================================================
import base64
import io
import cv2
import numpy as np
import pickle
from flask import Flask, send_from_directory
from flask_socketio import SocketIO
from gtts import gTTS
import mediapipe as mp
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# ============================================================================
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
# ============================================================================
app = Flask(__name__)
socketio = SocketIO(
    app,
    cors_allowed_origins="*",
    max_http_buffer_size=20_000_000
)

# ============================================================================
# Ø§Ù„Ø«ÙˆØ§Ø¨Øª ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
# ============================================================================
class Config:
    """Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""
    # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©
    WORDS = np.array([
        "Ø£Ù†Ø§", "Ù‡Ø°Ø§", "Ø§Ø±ÙŠØ¯", "Ø´ÙŠØ¡", "Ù‡Ù†Ø§", 
        "Ø§Ù„Ø§Ù†", "Ù„Ø§", "ÙÙŠ", "Ù…Ø§Ø°Ø§", "Ø§Ø®Ø±Ø³"
    ])
    
    # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©
    LETTERS_DICT = {
        0: 'Ø¹', 1: 'Ø§Ù„', 2: 'Ø£', 3: 'Ø¨', 4: 'Ø¯', 5: 'Ø¸', 6: 'Ø¶', 7: 'Ù',
        8: 'Ù‚', 9: 'Øº', 10: 'Ù‡', 11: 'Ø­', 12: 'Ø¬', 13: 'Ùƒ', 14: 'Ø®',
        15: 'Ù„Ø§', 16: 'Ù„', 17: 'Ù…', 18: 'Ù†', 19: 'Ø±', 20: 'Øµ', 21: 'Ø³',
        22: 'Ø´', 23: 'Øª', 24: 'Ø·', 25: 'Ø«', 26: 'Ø°', 27: 'Ø©', 28: 'Ùˆ',
        29: ' ', 30: 'ÙŠ', 31: 'Ø²'
    }
    
    # Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
    WORD_SEQUENCE_LENGTH = 30
    LETTER_REQUIRED_OCCURRENCES = 10
    
    # Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª
    WORD_MODEL_PATH = r".\utils\DL_model\checkpoints\best_model.keras"
    LETTER_MODEL_PATH = './utils/letter-detection-model/py38model-best.p'

# ============================================================================
# ØªÙ‡ÙŠØ¦Ø© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
# ============================================================================
class ModelManager:
    """Ø¥Ø¯Ø§Ø±Ø© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚"""
    
    def __init__(self):
        print("="*60)
        print("ğŸš€ Ø¨Ø¯Ø¡ ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… ÙƒØ´Ù Ù„ØºØ© Ø§Ù„Ø¥Ø´Ø§Ø±Ø©")
        print("="*60)
        
        self.word_model = self._build_word_model()
        self.letter_model = self._load_letter_model()
        self.mp_holistic = mp.solutions.holistic
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=True, 
            min_detection_confidence=0.3
        )
        
        print("="*60)
        print("âœ¨ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…!")
        print("="*60)
    
    def _build_word_model(self):
        """Ø¨Ù†Ø§Ø¡ ÙˆØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª"""
        print("ğŸ“¦ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ÙƒØ´Ù Ø§Ù„ÙƒÙ„Ù…Ø§Øª...")
        
        model = Sequential([
            LSTM(64, return_sequences=True, activation='tanh', input_shape=(30, 1662)),
            LSTM(128, return_sequences=True, activation='tanh'),
            LSTM(64, return_sequences=False, activation='tanh'),
            Dense(64, activation='relu'),
            Dense(32, activation='relu'),
            Dense(10, activation='softmax')
        ])
        
        model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        model.load_weights(Config.WORD_MODEL_PATH)
        
        # ØªØ³Ø®ÙŠÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        print("ğŸ”¥ ØªØ³Ø®ÙŠÙ† Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª...")
        dummy = np.zeros((1, 30, 1662), dtype=np.float32)
        _ = model.predict(dummy, verbose=0)
        print("âœ… Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø¬Ø§Ù‡Ø²!\n")
        
        return model
    
    def _load_letter_model(self):
        """ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø­Ø±ÙˆÙ"""
        print("ğŸ“¦ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ÙƒØ´Ù Ø§Ù„Ø­Ø±ÙˆÙ...")
        
        with open(Config.LETTER_MODEL_PATH, 'rb') as f:
            model_dict = pickle.load(f)
        
        model = model_dict['model']
        
        # ØªØ³Ø®ÙŠÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        print("ğŸ”¥ ØªØ³Ø®ÙŠÙ† Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø­Ø±ÙˆÙ...")
        try:
            dummy = np.zeros((1, 42), dtype=np.float32)
            _ = model.predict(dummy)
            print("âœ… Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø­Ø±ÙˆÙ Ø¬Ø§Ù‡Ø²!\n")
        except Exception as e:
            print(f"âš ï¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ù…Ù‘Ù„ (ØªÙ… ØªØ®Ø·ÙŠ Ø§Ù„ØªØ³Ø®ÙŠÙ†: {e})\n")
        
        return model

# ============================================================================
# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„ÙÙŠØ¯ÙŠÙˆ
# ============================================================================
class ImageProcessor:
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª"""
    
    @staticmethod
    def decode_base64_image(b64_string):
        """ÙÙƒ ØªØ´ÙÙŠØ± ØµÙˆØ±Ø© Ù…Ù† Base64"""
        try:
            img_bytes = base64.b64decode(b64_string)
            frame = cv2.imdecode(
                np.frombuffer(img_bytes, np.uint8), 
                cv2.IMREAD_COLOR
            )
            if frame is None:
                raise Exception("Ø§Ù„ØµÙˆØ±Ø© ØªØ§Ù„ÙØ©")
            return frame
        except Exception as e:
            raise Exception(f"Ø®Ø·Ø£ ÙÙŠ ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ù„ØµÙˆØ±Ø©: {e}")
    
    @staticmethod
    def mediapipe_detection(image, model):
        """ÙƒØ´Ù Ø§Ù„Ø¬Ø³Ù… ÙˆØ§Ù„ÙˆØ¬Ù‡ ÙˆØ§Ù„ÙŠØ¯ÙŠÙ† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… MediaPipe"""
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image.flags.writeable = False
        results = model.process(image)
        image.flags.writeable = True
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        return results
    
    @staticmethod
    def extract_keypoints(results):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬"""
        pose = np.array([
            [res.x, res.y, res.z, res.visibility] 
            for res in results.pose_landmarks.landmark
        ]).flatten() if results.pose_landmarks else np.zeros(33*4)
        
        face = np.array([
            [res.x, res.y, res.z] 
            for res in results.face_landmarks.landmark
        ]).flatten() if results.face_landmarks else np.zeros(468*3)
        
        left_hand = np.array([
            [res.x, res.y, res.z] 
            for res in results.left_hand_landmarks.landmark
        ]).flatten() if results.left_hand_landmarks else np.zeros(21*3)
        
        right_hand = np.array([
            [res.x, res.y, res.z] 
            for res in results.right_hand_landmarks.landmark
        ]).flatten() if results.right_hand_landmarks else np.zeros(21*3)
        
        return np.concatenate([pose, face, left_hand, right_hand])

# ============================================================================
# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª
# ============================================================================
class AudioProcessor:
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª ØµÙˆØªÙŠØ© Ù…Ù† Ø§Ù„Ù†Øµ"""
    
    @staticmethod
    def text_to_audio_base64(text, lang='ar'):
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØª Ø¨ØµÙŠØºØ© Base64"""
        try:
            audio_buffer = io.BytesIO()
            tts = gTTS(text=text, lang=lang)
            tts.write_to_fp(audio_buffer)
            audio_bytes = audio_buffer.getvalue()
            b64_string = base64.b64encode(audio_bytes).decode('utf-8')
            return f"data:audio/mp3;base64,{b64_string}"
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØª: {e}")
            return None

# ============================================================================
# Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø­Ø§Ù„Ø©
# ============================================================================
class SessionState:
    """Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø© Ù„Ù„ÙƒÙ„Ù…Ø§Øª ÙˆØ§Ù„Ø­Ø±ÙˆÙ"""
    # Ù„Ù„ÙƒÙ„Ù…Ø§Øª
    word_sequence = []
    
    # Ù„Ù„Ø­Ø±ÙˆÙ
    letter_text = ""
    letter_previous_char = None
    letter_char_counter = 0
    letter_data_aux = []
    letter_x = []
    letter_y = []

# ============================================================================
# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
# ============================================================================
models = ModelManager()
state = SessionState()

# ============================================================================
# Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª (Routes)
# ============================================================================
@app.route('/')
def index():
    """Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    return send_from_directory('templates', 'index.html')

@app.route('/translate')
def translate_page():
    """ØµÙØ­Ø© Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©"""
    return send_from_directory('templates', 'translate.html')

@app.route('/train')
def train_hub():
    """Ù…Ø±ÙƒØ² Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
    return send_from_directory('templates', 'train.html')

@app.route('/train/letters')
def train_letters():
    """ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø­Ø±ÙˆÙ"""
    return send_from_directory('templates', 'train_letters.html')

@app.route('/train/words')
def train_words():
    """ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙƒÙ„Ù…Ø§Øª"""
    return send_from_directory('templates', 'train_words.html')

@app.route('/test')
def test_page():
    """ØµÙØ­Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
    return send_from_directory('templates', 'test.html')

# ============================================================================
# Ù…Ø¹Ø§Ù„Ø¬Ø§Øª SocketIO - Ø§Ù„ÙƒÙ„Ù…Ø§Øª
# ============================================================================
@socketio.on('Word_frame')
def handle_word_frame(data):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¥Ø·Ø§Ø± ÙÙŠØ¯ÙŠÙˆ Ù„Ù„ÙƒÙ„Ù…Ø§Øª"""
    b64 = data.get("b64")
    if not b64:
        socketio.emit('result', "Ø®Ø·Ø£: Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª")
        return
    
    try:
        # ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ù„ØµÙˆØ±Ø©
        frame = ImageProcessor.decode_base64_image(b64)
        
        # ÙƒØ´Ù Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        with models.mp_holistic.Holistic(
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        ) as holistic:
            results = ImageProcessor.mediapipe_detection(frame, holistic)
            keypoints = ImageProcessor.extract_keypoints(results)
            
            # Ø¥Ø¶Ø§ÙØ© Ù„Ù„ØªØ³Ù„Ø³Ù„
            state.word_sequence.append(keypoints)
            state.word_sequence = state.word_sequence[-Config.WORD_SEQUENCE_LENGTH:]
            
            # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù†Ø¯ Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„ØªØ³Ù„Ø³Ù„
            if len(state.word_sequence) == Config.WORD_SEQUENCE_LENGTH:
                prediction = models.word_model.predict(
                    np.expand_dims(state.word_sequence, axis=0),
                    verbose=0
                )[0]
                
                predicted_word = Config.WORDS[np.argmax(prediction)]
                audio_url = AudioProcessor.text_to_audio_base64(predicted_word)
                
                # Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„ØªØ³Ù„Ø³Ù„
                state.word_sequence = []
                
                socketio.emit('result', {
                    "text": predicted_word,
                    "url": audio_url
                })
    
    except Exception as e:
        socketio.emit('result', f"Ø®Ø·Ø£: {str(e)}")

# ============================================================================
# Ù…Ø¹Ø§Ù„Ø¬Ø§Øª SocketIO - Ø§Ù„Ø­Ø±ÙˆÙ
# ============================================================================
@socketio.on('Letter_frame')
def handle_letter_frame(data):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¥Ø·Ø§Ø± ÙÙŠØ¯ÙŠÙˆ Ù„Ù„Ø­Ø±ÙˆÙ"""
    b64 = data.get("b64")
    if not b64:
        socketio.emit('result', "Ø®Ø·Ø£: Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª")
        return
    
    try:
        frame = ImageProcessor.decode_base64_image(b64)
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = models.hands.process(frame_rgb)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø±ÙØ¹ ÙŠØ¯ÙŠÙ† (Ø¥Ø´Ø§Ø±Ø© Ù„Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„ÙƒÙ„Ù…Ø©)
        if results.multi_hand_landmarks and len(results.multi_hand_landmarks) >= 2:
            if state.letter_text:
                audio_url = AudioProcessor.text_to_audio_base64(state.letter_text)
                socketio.emit('result', {
                    "text": "",
                    "url": audio_url
                })
                state.letter_text = ""
                state.letter_char_counter = 0
                state.letter_previous_char = None
            return
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙŠØ¯ ÙˆØ§Ø­Ø¯Ø©
        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª
                for landmark in hand_landmarks.landmark:
                    state.letter_x.append(landmark.x)
                    state.letter_y.append(landmark.y)
                
                # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                for landmark in hand_landmarks.landmark:
                    state.letter_data_aux.append(landmark.x - min(state.letter_x))
                    state.letter_data_aux.append(landmark.y - min(state.letter_y))
                
                # Ø§Ù„ØªÙ†Ø¨Ø¤
                prediction = models.letter_model.predict([
                    np.asarray(state.letter_data_aux)
                ])
                predicted_char = Config.LETTERS_DICT[int(prediction[0])]
                
                # Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©
                state.letter_data_aux = []
                state.letter_x = []
                state.letter_y = []
                
                # Ø¹Ø¯ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
                if predicted_char == state.letter_previous_char:
                    state.letter_char_counter += 1
                else:
                    state.letter_previous_char = predicted_char
                    state.letter_char_counter = 0
                
                # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø­Ø±Ù Ø¹Ù†Ø¯ Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
                if state.letter_char_counter >= Config.LETTER_REQUIRED_OCCURRENCES:
                    state.letter_text += predicted_char
                    state.letter_char_counter = 0
        
        socketio.emit('result', {
            "text": state.letter_text,
            "url": None
        })
    
    except Exception as e:
        print(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø­Ø±Ù: {e}")

# ============================================================================
# Ù…Ø¹Ø§Ù„Ø¬Ø§Øª SocketIO - Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
# ============================================================================
@socketio.on('Test_Letter')
def handle_test_letter(data):
    """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø­Ø±ÙˆÙ"""
    b64 = data.get("b64")
    target_char = data.get("target")
    
    if not b64:
        socketio.emit('test_response', "Ø®Ø·Ø£: Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª")
        return
    
    try:
        frame = ImageProcessor.decode_base64_image(b64)
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = models.hands.process(frame_rgb)
        
        confidence_score = 0.0
        predicted_char = None
        
        if results.multi_hand_landmarks:
            temp_x = []
            temp_y = []
            temp_data = []
            
            for hand_landmarks in results.multi_hand_landmarks:
                for landmark in hand_landmarks.landmark:
                    temp_x.append(landmark.x)
                    temp_y.append(landmark.y)
                
                for landmark in hand_landmarks.landmark:
                    temp_data.append(landmark.x - min(temp_x))
                    temp_data.append(landmark.y - min(temp_y))
                
                probabilities = models.letter_model.predict_proba([
                    np.asarray(temp_data)
                ])
                best_idx = np.argmax(probabilities[0])
                confidence_score = probabilities[0][best_idx]
                
                prediction = models.letter_model.predict([np.asarray(temp_data)])
                predicted_char = Config.LETTERS_DICT[int(prediction[0])]
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø«Ù‚Ø© Ø¥Ù„Ù‰ Ù†Ø³Ø¨Ø© Ù…Ø¦ÙˆÙŠØ© Ù…ÙÙ‡ÙˆÙ…Ø©
        human_score = np.interp(confidence_score, [0.2, 0.8], [50, 100])
        human_score = round(min(100, max(0, human_score)), 1)
        
        if predicted_char == target_char:
            result = f"âœ… ØµØ­ÙŠØ­! (Ø§Ù„Ø¯Ù‚Ø©: {human_score}%)"
        else:
            result = f"âŒ Ø®Ø·Ø£! Ø£Ù†Øª Ø£Ø¯ÙŠØª: {predicted_char} Ø¨Ø¯Ù‚Ø© {human_score}%"
        
        socketio.emit('test_response', result)
    
    except Exception as e:
        socketio.emit('test_response', f"Ø®Ø·Ø£: {str(e)}")

@socketio.on('Test_Word_Batch')
def handle_test_word(data):
    """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª"""
    frames_b64 = data.get("frames")
    target_word = data.get("target")
    
    if not frames_b64:
        socketio.emit('test_response', "Ø®Ø·Ø£: Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø·Ø§Ø±Ø§Øª")
        return
    
    try:
        # ÙÙƒ ØªØ´ÙÙŠØ± Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª
        frames = []
        for b64 in frames_b64:
            frame = ImageProcessor.decode_base64_image(b64)
            frames.append(frame)
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª
        sequence = []
        for frame in frames:
            with models.mp_holistic.Holistic(
                min_detection_confidence=0.5,
                min_tracking_confidence=0.5
            ) as holistic:
                results = ImageProcessor.mediapipe_detection(frame, holistic)
                keypoints = ImageProcessor.extract_keypoints(results)
                sequence.append(keypoints)
                sequence = sequence[-Config.WORD_SEQUENCE_LENGTH:]
                
                if len(sequence) == Config.WORD_SEQUENCE_LENGTH:
                    prediction = models.word_model.predict(
                        np.expand_dims(sequence, axis=0),
                        verbose=0
                    )[0]
                    
                    predicted_idx = np.argmax(prediction)
                    confidence = prediction[predicted_idx]
                    predicted_word = Config.WORDS[predicted_idx]
                    
                    sequence = []
        
        if predicted_word == target_word:
            result = f"âœ… ØµØ­ÙŠØ­! Ø§Ù„Ø¯Ù‚Ø©: {confidence:.0%}"
        else:
            result = f"âŒ Ø®Ø·Ø£! Ø£Ù†Øª Ø£Ø¯ÙŠØª: {predicted_word}"
        
        socketio.emit('test_response', result)
    
    except Exception as e:
        socketio.emit('test_response', f"Ø®Ø·Ø£: {str(e)}")

# ============================================================================
# ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
# ============================================================================
if __name__ == "__main__":
    socketio.run(app, host="0.0.0.0", port=5000)